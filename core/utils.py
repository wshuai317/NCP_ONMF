from sklearn.metrics import accuracy_score
import numpy as np
import pandas as pd
from sklearn.utils import linear_assignment_
import os
from filemanager import FileManager
import csv
import collections


def calculate_accuracy(cluster_assignments, true_classes):
    '''
    The function calculate the clustering accurary which use the ratio of correctly
    clustered points over the total number of points (in [0, 1], the higher the better)

         AC = sum_{i from 1 to N}   delta(si, map(ri))   / N

    where N is the total number of documents and delta(x, y) is the delta function
    that equals to one if x = y and 0 otherwise. ri and si are the obtained cluster
    label and the true label for the i-th data sample. Map(ri) is the permutation
    mapping function that maps each cluster label ri to the equivalent label in true labels.

    Input:
        cluster_assignments: an array contains cluster ids indicating the clustering
                            assignment of each data point with the same order in the data set

        true_classes: an array contains class ids indicating the true labels of each
                        data point with the same order in the data set

    Output: A number between 0 and 1. Poor clusterings have a purity close to 0 while a perfect clustering has a purity of 1
    '''

    ca = best_map(true_classes, cluster_assignments)
    return accuracy_score(ca, true_classes)

def best_map(L1, L2):
    if L1.__len__() != L2.__len__():
        print('size(L1) must == size(L2)')

    Label1 = np.unique(L1)
    nClass1 = Label1.__len__()
    Label2 = np.unique(L2)
    nClass2 = Label2.__len__()

    nClass = max(nClass1, nClass2)
    G = np.zeros((nClass, nClass))
    for i in range(nClass1):
        for j in range(nClass2):
            G[i][j] = np.nonzero((L1 == Label1[i]) * (L2 == Label2[j]))[0].__len__()
    c = linear_assignment_.linear_assignment(-G.T)[:, 1]
    newL2 = np.zeros(L2.__len__())
    for i in range(nClass2):
        for j in np.nonzero(L2 == Label2[i])[0]:
            if len(Label1) > c[i]:
                newL2[j] = Label1[c[i]]
    return newL2


def save_results_for_KM(root_dir, res_dict, method_name, dat_name):
    """
       The function is used to save generated results for K-means and its variants
    """
    res_dir = os.path.join(root_dir, 'results', method_name, dat_name) # get the result directory where the result is stored
    f_manager = FileManager(res_dir)
    f_path = os.path.join(res_dir, 'cls_quality.csv')
    f_manager.add_file(f_path)

    print f_path

    # Then, we save the results to one csv file like
    #        "seed_num"  "time"   "Purity"     "ARI"      "ACC"     "NMI" ...
    #     1      1         000      000         000        000       000  ... 
    #     2      2         000      000         000        000       000  ... 
    field_names = ['seed', 'time', 'Purity', 'ARI', 'ACC', 'NMI', 'd_W']  # fill out the field names for CSV

    with open(f_path, mode = 'wb') as csv_file:  # open the file, if not exist, create it
        writer = csv.DictWriter(csv_file, fieldnames = field_names) # create a writer which maps the dictionaries onto output rows in CSV
        writer.writeheader() # write the field names to the header
        for key in res_dict.keys():
            writer.writerow(res_dict[key])
 

def gather_results_by_seeds(root_dir, seeds):
    ''' This function is used to gather results generated by different initializations on NCP methods

    Args:
	root_dir the parent dir 
	seeds a list of seeds used
    Returns:
	a csv files generated with results collected from all files    
    '''
	
    size = len(seeds) # the number of initializations
    
    nmf_palm = np.ones((8000, size + 2)) * (-1)
    nmf_sncp = np.ones((8000, size + 2)) * (-1)
    onmf_cost_palm = np.ones((8000, size + 2)) * (-1)
    onmf_cost_sncp = np.ones((8000, size + 2)) * (-1)
    cost_palm = np.ones((8000, size + 2)) * (-1)
    cost_sncp = np.ones((8000, size + 2)) * (-1)
    WH_nr = np.ones((8000, size + 2)) * (-1)
    ortho_nr = np.ones((8000, size + 2)) * (-1)
    
    cls_acc = np.ones((8000, size + 2)) * (-1)
    for seed in seeds:
	res_path = os.path.join(root_dir, 'seed' + str(seed), 'res.csv')
	cls_path = os.path.join(root_dir, 'seed' + str(seed), 'cls_quality.csv')
	if not os.path.exists(res_path) or not os.path.exists(cls_path):
	    raise ValueError('Error: the result path cannot be found!')

        df = pd.read_csv(res_path, header = 0)
        # convet the dataframe into a numpy mat
        res_arr = df.as_matrix()

        #print res_arr[0, 0]	
	dim = res_arr.shape[0]
        	
	# move the nmf cost VS palm
	nmf_palm[0:dim, seed - 1] = res_arr[:, 0]
	# move the cost VS palm
	cost_palm[0:dim, seed - 1] = res_arr[:, 1]
	# move the nmf cost VS sncp
	nmf_sncp[0:dim, seed - 1] = res_arr[:, 2]
	# move the onmf cost VS SNCP
	onmf_cost_sncp[0:dim, seed - 1] = res_arr[:, 3]
	# move the onmf cost VS PALM
	onmf_cost_palm[0:dim, seed - 1] = res_arr[:, 4]
	# move the cost VS SNCP
	cost_sncp[0:dim, seed - 1] = res_arr[:, 5]
	# move the WH_nr
	WH_nr[0:dim - 1, seed - 1] = res_arr[1:, 12].astype(float) + res_arr[1:, 13].astype(float)
	# move the ortho nr
	ortho_nr[0:dim, seed - 1] = res_arr[:, 14]
	
	df2 = pd.read_csv(cls_path, header = 0)
	cls_arr = df2.as_matrix()
	# move the cluster accuracy VS SNCP
	dim = cls_arr.shape[0]
	cls_acc[0:dim, seed - 1] = cls_arr[:, 5]

    

    f_manager = FileManager(root_dir)
        
    nmf_palm_path = os.path.join(root_dir, 'nmf_cost_palm.csv')
    f_manager.add_file(nmf_palm_path)
    m01 = np.mean(nmf_palm[:, 0:size], axis = 1)
    std01 = np.std(nmf_palm[:, 0:size], axis = 1)
    nmf_palm[:, size] = m01.T
    nmf_palm[:, size + 1] = std01.T
    np.savetxt(nmf_palm_path, np.asmatrix(nmf_palm), delimiter = ',', fmt = '%.30f')
    nmf_sncp_path = os.path.join(root_dir, 'nmf_cost_sncp.csv')
    f_manager.add_file(nmf_sncp_path)
    m02 = np.mean(nmf_sncp[:, 0:size], axis = 1)
    std02 = np.std(nmf_sncp[:, 0:size], axis = 1)
    nmf_sncp[:, size] = m02.T
    nmf_sncp[:, size + 1] = std02.T
    np.savetxt(nmf_sncp_path, np.asmatrix(nmf_sncp), delimiter = ',', fmt = '%.30f')
    onmf_palm_path = os.path.join(root_dir, 'onmf_cost_palm.csv')
    f_manager.add_file(onmf_palm_path)
    m1 = np.mean(onmf_cost_palm[:, 0:size], axis = 1)
    std1 = np.std(onmf_cost_palm[:, 0:size], axis = 1)
    onmf_cost_palm[:, size] = m1.T
    onmf_cost_palm[:, size + 1] = std1.T
    np.savetxt(onmf_palm_path, np.asmatrix(onmf_cost_palm), delimiter = ',', fmt='%.30f')
    onmf_sncp_path = os.path.join(root_dir, 'onmf_cost_sncp.csv')
    f_manager.add_file(onmf_sncp_path)
    m2 = np.mean(onmf_cost_sncp[:, 0:size], axis = 1)
    std2 = np.std(onmf_cost_sncp[:, 0:size], axis = 1)
    onmf_cost_sncp[:, size] = m2.T
    onmf_cost_sncp[:, size + 1] = std2.T
    np.savetxt(onmf_sncp_path, np.asmatrix(onmf_cost_sncp), delimiter = ',', fmt = '%.30f')
    sncp_path = os.path.join(root_dir, 'cost_sncp.csv')
    f_manager.add_file(sncp_path)
    m3 = np.mean(cost_sncp[:, 0:size], axis = 1)
    std3 = np.std(cost_sncp[:, 0:size], axis = 1)
    cost_sncp[:, size] = m3.T
    cost_sncp[:, size + 1] = std3.T
    np.savetxt(sncp_path, np.asmatrix(cost_sncp), delimiter = ',', fmt = '%.30f')
    palm_path = os.path.join(root_dir, 'cost_palm.csv')
    f_manager.add_file(palm_path)
    m4 = np.mean(cost_palm[:, 0:size], axis = 1)
    std4 = np.std(cost_palm[:, 0:size], axis = 1)
    cost_palm[:, size] = m4.T
    cost_palm[:, size + 1] = std4.T
    np.savetxt(palm_path, np.asmatrix(cost_palm), delimiter = ',', fmt = '%.30f')
    WH_nr_path = os.path.join(root_dir, 'WH_NR.csv')
    f_manager.add_file(WH_nr_path)
    m5 = np.mean(WH_nr[:, 0:size], axis = 1)
    std5 = np.std(WH_nr[:, 0:size], axis = 1)
    WH_nr[:, size] = m5.T
    WH_nr[:, size + 1] = std5.T
    np.savetxt(WH_nr_path, np.asmatrix(WH_nr), delimiter = ',', fmt = '%.30f')
    ortho_nr_path = os.path.join(root_dir, 'ortho_NR.csv')
    f_manager.add_file(ortho_nr_path)
    m6 = np.mean(ortho_nr[:, 0:size], axis = 1)
    std6 = np.std(ortho_nr[:, 0:size], axis = 1)
    ortho_nr[:, size] = m6.T
    ortho_nr[:, size + 1] = std6.T
    np.savetxt(ortho_nr_path, np.asmatrix(ortho_nr), delimiter = ',', fmt = '%.30f')
    
    cls_acc_path = os.path.join(root_dir, 'cls_acc.csv')
    f_manager.add_file(cls_acc_path)
    m7 = np.mean(cls_acc[:, 0:size], axis = 1)
    std7 = np.std(cls_acc[:, 0:size], axis = 1)
    cls_acc[:, size] = m7.T
    cls_acc[:, size + 1] = std7.T
    np.savetxt(cls_acc_path, np.asmatrix(cls_acc), delimiter = ',', fmt = '%.30f')

        
if __name__ == "__main__":	
    root_dir = '/home/wl318/cloud/JMLR2020/results/onmf/sncp1/syn_otlr#-3/cls10/inner0.003&gamma1.1&mul0&nu1e-10'
    #root_dir = '/home/wl318/cloud/JMLR2020/results/onmf/sncp2_new/syn_otlr#-3/cls10/W_noboundW0.51H1/inner0.01&gamma1.1&mul0&nu1e-10'
    seeds = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    gather_results_by_seeds(root_dir, seeds)
